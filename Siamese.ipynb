{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4Q1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "c9sPD33yYgcL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Problem 1: Speaker Verification**\n",
        "\n",
        "Importing all the libraries"
      ]
    },
    {
      "metadata": {
        "id": "EAgzga9JcCBv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "plzmVFcGYt84",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mounting the google drive files to load the input data"
      ]
    },
    {
      "metadata": {
        "id": "p-Gz7YnFejR6",
        "colab_type": "code",
        "outputId": "44a6c7bd-b749-4020-b897-8b0871736515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "directory='/content/gdrive/My Drive/Masters/DeepLearning/Homework4/Data/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mt9XKMcmY1c-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function to read the pickle objects"
      ]
    },
    {
      "metadata": {
        "id": "X6b4HYJreQQT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_pkl(name):\n",
        "  with open(name+'.pkl', 'rb') as f:\n",
        "      X = pickle.load(f)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R2TQwl-JY7K1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the training & test dataset"
      ]
    },
    {
      "metadata": {
        "id": "Tpc16SoTf6oM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train=read_pkl(directory+'hw4_trs')\n",
        "test=read_pkl(directory+'hw4_tes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOywMgFoY-WB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function to compute the STFT of the input data"
      ]
    },
    {
      "metadata": {
        "id": "nsabAUOcjJNW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def stft_data(X):\n",
        "  for i in range(X.shape[0]):\n",
        "    S=librosa.stft(X[i], n_fft=1024, hop_length=hop_length)\n",
        "    spectrogram=S if not i else np.vstack((spectrogram,S))\n",
        "  return spectrogram.reshape((X.shape[0],hop_length+1,-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iqMXYTuuZIHC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compute the magnitude of the stft of the training & test dataset"
      ]
    },
    {
      "metadata": {
        "id": "vDBPEchIBHyx",
        "colab_type": "code",
        "outputId": "593198b5-7bc8-40c8-c50a-aba58014aa57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "hop_length=512\n",
        "train_spectrogram=np.abs(stft_data(train))\n",
        "test_spectrogram=np.abs(stft_data(test))\n",
        "print(train_spectrogram.shape)\n",
        "print(test_spectrogram.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 513, 32)\n",
            "(200, 513, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fs5tRzpGZT6-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Function to define the RNN architecture"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YoTTwMJrfDTy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_architecture(lstm_sizes,X,keep_prob,reuse,rnn_tuple_state):\n",
        "  with tf.name_scope('lstm'):  # LSTM layer\n",
        "    lstms=[tf.contrib.rnn.LSTMCell(size,initializer=tf.contrib.layers.xavier_initializer(),reuse=reuse,state_is_tuple=True) for size in lstm_sizes]\n",
        "    drops=[tf.contrib.rnn.DropoutWrapper(lstm,output_keep_prob=keep_prob) for lstm in lstms]  # Add dropout to the LSTM cell\n",
        "    cell=tf.contrib.rnn.MultiRNNCell(drops,state_is_tuple=True)  # Stack up multiple LSTM layers for deep learning\n",
        "    lstm_output,final_state=tf.nn.dynamic_rnn(cell,X,initial_state=rnn_tuple_state)\n",
        "  \n",
        "  with tf.name_scope('fully_connected'):  # Fully connected layer to get the required latent embedding dimension\n",
        "    embedding=tf.layers.dense(lstm_output[:,-1,:],128,kernel_initializer=tf.contrib.layers.xavier_initializer(),activation=tf.nn.tanh,reuse=reuse)\n",
        "    \n",
        "  return embedding,final_state,cell"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sh0hSinOZt5C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function to compute the similarity between 2 embeddings"
      ]
    },
    {
      "metadata": {
        "id": "JrRwTqZlavmY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_lstm_layers(lstm_sizes,X1,X2,keep_prob,rnn_tuple_state):  # Create the LSTM layers\n",
        "# Parameters: lstm_sizes=number of hidden states in each lstm cell, X=input, keep_prob=1-Dropout probability\n",
        "  embedding1,final_state1,cell=rnn_architecture(lstm_sizes,X1,keep_prob,False,rnn_tuple_state)  # Latent embedding of the 1st speaker\n",
        "  embedding2,final_state2,cell=rnn_architecture(lstm_sizes,X2,keep_prob,True,rnn_tuple_state)  # Latent embedding of the 2nd speaker\n",
        "  output=tf.nn.sigmoid(tf.reduce_sum(embedding1*embedding2, 1, keep_dims=True))  # Similarity between the 2 speakers\n",
        "  return output,cell,final_state1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CRUmFdSvaFGb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function to calculate the loss of the network"
      ]
    },
    {
      "metadata": {
        "id": "iSHAZbQKKGIk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculate_loss(y,yhat,learning_rate):\n",
        "  loss=tf.reduce_mean(-tf.cast(y,tf.float32)*tf.log(yhat)-tf.cast(1-y,tf.float32)*tf.log(1-yhat))\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "  return loss,optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aN2UR3SxaMPE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function to build the minibatch from the input data"
      ]
    },
    {
      "metadata": {
        "id": "bqy1emk1MSGM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_minibatch(spectrogram,index):\n",
        "  size=[]\n",
        "  for i in range(spectrogram.shape[0]):\n",
        "    if not 10*index<i<10*index+9:\n",
        "      size.append(i)\n",
        "  size=np.array(size)\n",
        "  x=np.zeros((batch_size,2,spectrogram.shape[2],spectrogram.shape[1]))\n",
        "  y=np.zeros(batch_size)\n",
        "  count=0\n",
        "  for i in range(9):\n",
        "    for j in range(i+1,10):\n",
        "      x[count,0]=spectrogram[10*index+i].T\n",
        "      x[count,1]=spectrogram[10*index+j].T\n",
        "      y[count]=1\n",
        "      count+=1\n",
        "  rand1=np.random.randint(low=10*index,high=10*index+9,size=batch_size//2)\n",
        "  rand2=np.random.choice(size,batch_size//2,replace=False)\n",
        "  rand3=np.random.choice([0,1],batch_size//2)\n",
        "  for i in range(batch_size//2):\n",
        "    x[count+i,rand3[i]]=spectrogram[rand1[i]].T\n",
        "    x[count+i,1-rand3[i]]=spectrogram[rand2[i]].T\n",
        "  indices=np.arange(batch_size)\n",
        "  np.random.shuffle(indices)\n",
        "  return x[indices],y[indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "URNYuFDxaZHO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function to compute the test accuracy"
      ]
    },
    {
      "metadata": {
        "id": "RMTJ-UBpjdZM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getTestAccuracy(n_batches):\n",
        "  accuracy=np.zeros(n_batches)\n",
        "  test_state=np.zeros((len(lstm_sizes),2,batch_size,lstm_sizes[0]))\n",
        "  for i in range(n_batches):\n",
        "    xte,yte=load_minibatch(test_spectrogram,i)\n",
        "    feed_dict={input1:xte[:,0,...],input2:xte[:,1,...],keep_prob:1,initial_state:test_state}\n",
        "    te_output,test_state=sess.run([lstm_output,final_state],feed_dict=feed_dict)\n",
        "    te_output=np.round(te_output)\n",
        "    accuracy[i]=np.sum(te_output[:,0]==yte)*100/yte.shape[0]\n",
        "  return np.mean(accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CVCpkxvfafFx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Initializing the parameters of LSTM network"
      ]
    },
    {
      "metadata": {
        "id": "q8fd0_JvHg_R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()  # To reset all the parameters of the graph for every execution\n",
        "tf.random.set_random_seed(0)\n",
        "batch_size=90\n",
        "n_batches=50  # Number of minibatches\n",
        "learning_rate=0.00001\n",
        "lstm_sizes=[256,256]  # Hidden units in the LSTM architecture\n",
        "input1=tf.placeholder(tf.float32,[batch_size,None,hop_length+1],name='input1')  # Placeholder for the 1st speaker\n",
        "input2=tf.placeholder(tf.float32,[batch_size,None,hop_length+1],name='input2')  # Placeholder for the 2nd speaker\n",
        "output=tf.placeholder(tf.int32,[batch_size],name='output')  \n",
        "keep_prob=tf.placeholder(tf.float32,name='keep_prob')  # keep_prob=1-dropout_prob\n",
        "initial_state=tf.placeholder(tf.float32,[len(lstm_sizes),2,batch_size,lstm_sizes[0]],name='initial_state')  # Initial state of the LSTM network\n",
        "state_per_layer_list = tf.unstack(initial_state, axis=0)\n",
        "rnn_tuple_state = tuple([tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1]) for idx in range(len(lstm_sizes))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7v3l4UVbEaC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training the LSTM network"
      ]
    },
    {
      "metadata": {
        "id": "Vi-URDhJvxRw",
        "colab_type": "code",
        "outputId": "8b5e64fe-8eed-471a-8707-a5e4da3db907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "lstm_output,lstm_cell,final_state=build_lstm_layers(lstm_sizes,input1,input2,keep_prob,rnn_tuple_state)\n",
        "loss,optimizer=calculate_loss(output,lstm_output,learning_rate)\n",
        "sess=tf.InteractiveSession()\n",
        "tf.global_variables_initializer().run()  # Initialize all the graph variables\n",
        "maxEpoch=131\n",
        "np.random.seed(0)\n",
        "for e in range(maxEpoch):\n",
        "  l_t=0\n",
        "  state=np.zeros((len(lstm_sizes),2,batch_size,lstm_sizes[0]))\n",
        "  for i in range(n_batches):\n",
        "    x,y=load_minibatch(train_spectrogram,i)\n",
        "    feed_dict={input1:x[:,0,...],input2:x[:,1,...],output:y,keep_prob:0.98,initial_state:state}\n",
        "    train_op,state,l_train,_=sess.run([lstm_output,final_state,loss,optimizer],feed_dict=feed_dict)\n",
        "    l_t+=l_train\n",
        "  if not e%10:\n",
        "    print('Epoch:{} Training loss:{}'.format(e,l_t))\n",
        "print('Test Accuracy:{} %'.format(getTestAccuracy(20)))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 Training loss:38.93625956773758\n",
            "Epoch:10 Training loss:34.823713064193726\n",
            "Epoch:20 Training loss:34.729903876781464\n",
            "Epoch:30 Training loss:34.69943916797638\n",
            "Epoch:40 Training loss:34.68405079841614\n",
            "Epoch:50 Training loss:34.6759672164917\n",
            "Epoch:60 Training loss:34.67029792070389\n",
            "Epoch:70 Training loss:34.666658997535706\n",
            "Epoch:80 Training loss:34.664449870586395\n",
            "Epoch:90 Training loss:34.66307157278061\n",
            "Epoch:100 Training loss:34.66163271665573\n",
            "Epoch:110 Training loss:34.66065865755081\n",
            "Epoch:120 Training loss:34.660042226314545\n",
            "Epoch:130 Training loss:34.65940374135971\n",
            "Test Accuracy:60.222222222222214 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OXAOT0SM0Oe9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}